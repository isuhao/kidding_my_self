<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<!-- 
	Copyright (C) 2007, 2008, 2009, 2010, 2011. PARP Research Group.
	<http://perception.inf.um.es>
	University of Murcia, Spain.

	This file is part of the QVision library.

	QVision is free software: you can redistribute it and/or modify
	it under the terms of the GNU Lesser General Public License as
	published by the Free Software Foundation, version 3 of the License.

	QVision is distributed in the hope that it will be useful,
	but WITHOUT ANY WARRANTY; without even the implied warranty of
	MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
	GNU Lesser General Public License for more details.

	You should have received a copy of the GNU Lesser General Public
	License along with QVision. If not, see <http://www.gnu.org/licenses/>.
-->

<html><head><meta http-equiv="content-Type" content="text/html;charset=UTF-8">
<title>QVision: Qt&#39;s Image, Video and Computer Vision Library</title>
<meta name="title" content="QVision" />
<meta name="dc.title" content="QVision" />
<meta name="url" content="http://perception.inf.um.es/QVision" />
<meta name="author" content="PARP Research Group - http://perception.inf.um.es" />
<meta name="revisit-after" content="30 DAYS"/>
<meta name="robots" content="index,follow"/>
<meta name="classification" content="*">
<meta name="rating" content="Safe For Kids">
<meta name="distribution" content="GLOBAL"/>
<meta name="description" content="Qt's Image, Video and Computer Vision Library"/>
<meta name="page-topic" content="Computer Vision research and prototype programming"/>
<meta name="geo.country" content="ES" />

<!--
Keywords:
By license:		open source, gnu, lgpl, gpl, free
By theme:		computer vision, image processing, robotics, programming, source, development
By usage:		library, toolkit, framework, prototype, application
By programming specs:	object oriented, c++, block programming, reusability, gui, graphical, parallel computing, high performance, GPU, prototyping
Interoperability with:	Qt, GSL, GNU Scientific library, OpenCV, CGAL, QWT, CUDA, mplayer, IPP, Intel Image Performance Primitives, blas, lapack
Functionallity:		image features, matrix algebra, projective geometry, mser, function minimization, function optimization, canny operator, harris operator, corner detection, performance evaluation, cpu usage, graphical interface
Main data-types:	matrix, vector, tensor, quaternion, image, polyline
Video sources:		webcam, camera, stream
Devices:		embedded, desktop computer, laptop, mini-laptop
Authors:		PARP research group. University of Murcia, Spain.
-->

<meta name="keywords" content="augmented reality, sfm, structure from motion, open source, gnu, lgpl, gpl, free, computer vision, image processing, robotics, programming, source, development, library, toolkit, framework, prototype, application, object oriented, c++, block programming, reusability, gui, graphical, parallel computing, high performance, GPU, prototyping, Qt, GSL, GNU Scientific library, OpenCV, CGAL, QWT, CUDA, mplayer, IPP, Intel Image Performance Primitives, blas, lapack, image features, matrix algebra, projective geometry, mser, function minimization, function optimization, canny operator, harris operator, corner detection, performance evaluation, cpu usage, graphical interface, matrix, vector, tensor, quaternion, image, polyline, webcam, camera, stream, embedded, desktop computer, laptop, mini-laptop, University of Murcia, Spain, PARP research group, vision por computador"/>
<meta http-equiv="keywords" content="augmented reality, sfm, structure from motion, open source, gnu, lgpl, gpl, free, computer vision, image processing, robotics, programming, source, development, library, toolkit, framework, prototype, application, object oriented, c++, block programming, reusability, gui, graphical, parallel computing, high performance, GPU, prototyping, Qt, GSL, GNU Scientific library, OpenCV, CGAL, QWT, CUDA, mplayer, IPP, Intel Image Performance Primitives, blas, lapack, image features, matrix algebra, projective geometry, mser, function minimization, function optimization, canny operator, harris operator, corner detection, performance evaluation, cpu usage, graphical interface, matrix, vector, tensor, quaternion, image, polyline, webcam, camera, stream, embedded, desktop computer, laptop, mini-laptop, University of Murcia, Spain, PARP research group, vision por computador"/>
<meta http-equiv="pragma" content="no-cache"/>
<meta http-equiv="title" content="QVision"/>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="tabs.css" rel="stylesheet" type="text/css" />
<link rel="shortcut icon" href="favicon.ico" />
</head><body>

<table width="100%"><tr>
	<td><a href="http://perception.inf.um.es/"><img src="parp.png" border="0" /> <big>PARP Research Group</big></a></td>
	<td align="right"><a href="http://www.um.es/"><big>Universidad de Murcia</big> <img src="um.png" border="0" /></a></td>
</tr></table>

<hr /><br />

<table width="95%" align="center"><tr><td>

<!-- Generated by Doxygen 1.6.3 -->
<script type="text/javascript"><!--
var searchBox = new SearchBox("searchBox", "search",false,'Search');
--></script>
<div class="navigation" id="top">
  <div class="tabs">
    <ul>
      <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&nbsp;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
          <form id="FSearchBox" action="search.php" method="get">
            <img id="MSearchSelect" src="search/search.png" alt=""/>
            <input type="text" id="MSearchField" name="query" value="Search" size="20" accesskey="S" 
                   onfocus="searchBox.OnSearchFieldFocus(true)" 
                   onblur="searchBox.OnSearchFieldFocus(false)"/>
          </form>
        </div>
      </li>
    </ul>
  </div>
  <div class="navpath"><a class="el" href="ManualSections.html">The manual</a>
  </div>
</div>
<div class="contents">


<h1><a class="anchor" id="AdvancedExampleBlockStructured">An advanced block-oriented example </a></h1><p>In this section we will create a complex block-oriented application, that runs several block objects and transfers data between them. This application will ingenuously solve the problem of <em>moving edge detection</em>: in a video sequence, containing both still and moving objects, detect edges corresponding only to the moving objects.</p>
<p>To do so, our application will add a movement detector to the example application described at section <a class="el" href="FirstExampleBlockStructuredApplication.html">Creating the first block-oriented application</a>, which detects edges at the input frames from a video sequence, using the Canny edge detector. The movement information will be used to identify the segments corresponding to moving objects.</p>
<p>The movement detection will provide a binary movement response image, containing a <em>true</em> value at each pixel corresponding to a moving object or surface. The application will obtained this image, by simply thresholding the absolute difference between the last image read from the video sequence, and the image read back at a fixed number of frames in the video sequence.</p>
<p>We will use three new block objects of type QVImageRetarderBlock, <a class="el" href="classQVAbsDiff__uCharC1Block.html">QVAbsDiff_uCharC1Block</a>, and <a class="el" href="classQVCompareC__uCharC1Block.html">QVCompareC_uCharC1Block</a> to obtain the binary image. First we will add the necessary includes in the original Canny edge detector example application:</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor">#include &lt;QVImageRetarderBlock&gt;</span>
<span class="preprocessor">#include &lt;qvippblocks.h&gt;</span>
</pre></div><p>Next we add the code to create the block objects, and link them to obtain the movement response image. It should be created before the call to the <a class="el" href="classQVApplication.html#a629aa9b6d8aa09fdb5ed379167c84af4">QVApplication::exec()</a> method, in the <em>main</em> function of the Canny example:</p>
<div class="fragment"><pre class="fragment">QVImageRetarderBlock&lt;uChar,1&gt; retarderBlock(<span class="stringliteral">&quot;Image retarder block&quot;</span>);
<a class="code" href="classQVAbsDiff__uCharC1Block.html" title="Calculate absolute difference between corresponding pixels of the two images or between...">QVAbsDiff_uCharC1Block</a> absDiffBlock(<span class="stringliteral">&quot;Absolute difference block&quot;</span>);
<a class="code" href="classQVCompareC__uCharC1Block.html" title="Compares pixel values of two images, or pixel values of an image to a constant value...">QVCompareC_uCharC1Block</a> compareCBlock(<span class="stringliteral">&quot;Threshold block&quot;</span>);
<a class="code" href="classQVImageCanvas.html" title="Display widget for QVImage objects and other data types.">QVImageCanvas</a> movementDisplayer(<span class="stringliteral">&quot;Movement detector&quot;</span>);

compareCBlock.setPropertyValue&lt;IppCmpOp&gt;(<span class="stringliteral">&quot;ippCmpOp&quot;</span>, ippCmpGreater);
compareCBlock.setPropertyValue&lt;uChar&gt;(<span class="stringliteral">&quot;value&quot;</span>, 32);

videoReader.linkProperty(&amp;retarderBlock, <span class="stringliteral">&quot;Input image&quot;</span>);
videoReader.linkProperty(&amp;absDiffBlock, <span class="stringliteral">&quot;qvimage_pSrc1&quot;</span>);
retarderBlock.linkProperty(<span class="stringliteral">&quot;Output image&quot;</span>, &amp;absDiffBlock, <span class="stringliteral">&quot;qvimage_pSrc2&quot;</span>, QVProcessingBlock::SynchronousLink);
absDiffBlock.linkProperty(<span class="stringliteral">&quot;qvimage_pDst&quot;</span>, &amp;compareCBlock, <span class="stringliteral">&quot;qvimage_pSrc&quot;</span>, QVProcessingBlock::SynchronousLink);
compareCBlock.linkProperty(<span class="stringliteral">&quot;qvimage_pDst&quot;</span>, movementDisplayer);
</pre></div><p>The following image displays the resulting application block structure:</p>
<div align="center">
<img src="cannyPlusMovementDetectorExample.png" alt="cannyPlusMovementDetectorExample.png"/>
</div>
<p>The application can be compiled and executed as the original Canny example:</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"># qmake-qt4; make</span>
<span class="preprocessor"></span>
<span class="preprocessor"># ./blockExample --URL=moving-hartley.mpg</span>
</pre></div><p>The <a href="http://perception.inf.um.es/public_data/videos/misc/moving-hartley.mpg">moving-hartley.mpg</a> is one of our test videos. It shows a static lab scene where a hand is shaking a computer vision bible. The following is a screen capture of what the application displays in the three image canvas:</p>
<div align="center">
<img src="hartley-edge-movement-detector.png" alt="hartley-edge-movement-detector.png"/>
</div>
<h2><a class="anchor" id="CombiningEdgeAndMovementInformation">
Combining edge and movement information</a></h2>
<p>To identify the moving edges in the input video sequence, the application must combine the information contained in the edge response image, and in the movement response image. The first approach to combine them can be a pixel-wise image product of both images. We can use the class <a class="el" href="classQVMul__uCharC1Block.html">QVMul_uCharC1Block</a> to create a processing block that obtains the product of both the edge response image, and the movement response image:</p>
<div class="fragment"><pre class="fragment"><a class="code" href="classQVMul__uCharC1Block.html" title="Adds, subtracts, or multiplies pixel values of two source images and places the results...">QVMul_uCharC1Block</a> multBlock(<span class="stringliteral">&quot;Product block&quot;</span>);
<a class="code" href="classQVImageCanvas.html" title="Display widget for QVImage objects and other data types.">QVImageCanvas</a> movingEdgesDisplayer(<span class="stringliteral">&quot;Detected moving edges&quot;</span>);

cannyBlock.linkProperty(<span class="stringliteral">&quot;Output image&quot;</span>, &amp;multBlock, <span class="stringliteral">&quot;qvimage_pSrc1&quot;</span>, QVProcessingBlock::SynchronousLink);
compareCBlock.linkProperty(<span class="stringliteral">&quot;qvimage_pDst&quot;</span>, &amp;multBlock, <span class="stringliteral">&quot;qvimage_pSrc2&quot;</span>, QVProcessingBlock::SynchronousLink);
multBlock.linkProperty(<span class="stringliteral">&quot;qvimage_pDst&quot;</span>, movingEdgesDisplayer);
</pre></div><p>The resulting image (that will be displayed in the <em>movingEdgesDisplayer</em> image canvas) will contain the value of <em>255</em> at the pixels active in both the movement response image, and the edge response image. For the rest of the pixels, the image will contain the <em>0</em> value.</p>
<p>The final application block structure, including the image multiplier block, is the following:</p>
<div align="center">
<img src="finalMovementDetectorExample.png" alt="finalMovementDetectorExample.png"/>
</div>
<p>The following image shows a screen-shot of the execution of the application with the video file <em>moving-hartley.mpg</em>. The bottom-right image canvas shows the moving edges identified by the application, on the actual frame of the video sequence.</p>
<div align="center">
<img src="hartley-combined-edge-movement-detector.png" alt="hartley-combined-edge-movement-detector.png"/>
</div>
<p>The resulting detection is a bit poor and obtains discontinuous edges and short isolated line segments.</p>
<p>To illustrate the creation and usage of custom processing blocks, the following section of the manual <a class="el" href="CreatingCustomProcessingBlocks.html">Creating custom processing blocks</a> proposes a better moving edges detector. It requires the creation of a custom processing block, that performs a better combination of the edge and movement response images than a pixel-wise product. </p>
</div>
</td></tr></table>

<br /><hr><br />
<center><a href="http://perception.inf.um.es/QVision">QVision framework</a>.
<a href="http://perception.inf.um.es">PARP research group</a>.
Copyright &copy; 2007, 2008, 2009, 2010, 2011.</center>
<br />
</body>
</html>
